# ğŸŒ¾ DetecÃ§Ã£o de CabeÃ§as de Trigo com YOLOv3

Este projeto tem como objetivo aplicar tÃ©cnicas de visÃ£o computacional para detectar automaticamente espigas de trigo em imagens reais de plantaÃ§Ãµes, utilizando o modelo YOLOv3. A proposta contribui com a agricultura de precisÃ£o, otimizando a contagem e monitoramento de lavouras.

## ğŸ“Œ Objetivo

Automatizar a detecÃ§Ã£o de espigas de trigo com alta precisÃ£o e velocidade, usando deep learning, e avaliar o desempenho do modelo em imagens com objetos pequenos e densamente agrupados.

---

## ğŸ› ï¸ Ferramentas Utilizadas

- **YOLOv3**: Modelo de detecÃ§Ã£o de objetos em tempo real.
- **Python**: Linguagem de programaÃ§Ã£o principal.
- **Google Colab**: Ambiente de treinamento com suporte a GPU (A100).
- **Google Drive**: Armazenamento do dataset e integraÃ§Ã£o com o Colab.
- **OpenCV**: Leitura e visualizaÃ§Ã£o das imagens e bounding boxes.
- **Matplotlib**: GeraÃ§Ã£o de grÃ¡ficos para anÃ¡lise visual.
- **Dataset:** [Global Wheat Head Detection](https://www.kaggle.com/competitions/global-wheat-detection/data)

---

## ğŸ—‚ï¸ Estrutura do Projeto

â”œâ”€â”€ yolov3.yaml # Arquitetura do modelo YOLOv3
â”œâ”€â”€ data.yaml # ConfiguraÃ§Ã£o do dataset (treino, validaÃ§Ã£o, classes)
â”œâ”€â”€ train.py # CÃ³digo de treinamento
â”œâ”€â”€ visualize_labels.py # VisualizaÃ§Ã£o das bounding boxes
â”œâ”€â”€ README.md # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ runs/detect/ # Resultados do treinamento
â””â”€â”€ notebooks/ # Notebooks complementares (grÃ¡ficos e anÃ¡lise)
---

## ğŸ“ Dataset

Utilizamos o dataset **Global Wheat Head Detection**, composto por milhares de imagens com anotaÃ§Ãµes em formato YOLO. Cada imagem contÃ©m espigas de trigo marcadas com coordenadas normalizadas, o que permite treinar o modelo de detecÃ§Ã£o de forma supervisionada.

---

## ğŸ”„ PrÃ©-processamento

- Redimensionamento das imagens para **640x640 pixels**
- ConversÃ£o das anotaÃ§Ãµes para o formato YOLO (`.txt`)
- SeparaÃ§Ã£o do conjunto de dados: **80% para treino**, **20% para validaÃ§Ã£o**
- VisualizaÃ§Ã£o inicial das caixas (bounding boxes) para validaÃ§Ã£o visual

---

## âš™ï¸ Treinamento

```python
model = YOLO('yolov3.yaml')

model.train(
    data='data.yaml',
    epochs=20,
    imgsz=640,
    batch=16,
    name='wheat_yolov3',
    project='runs/detect'
)
```

- Ã‰pocas: 20
- Tamanho da imagem: 640Ã—640
- Batch size: 16
- Taxa de aprendizado: PadrÃ£o do otimizador Adam
- Ambiente: Google Colab com GPU A100

## ğŸ“Š Resultados

| **MÃ©trica**       | **Valor Aproximado Final** |
|-------------------|----------------------------|
| Box Loss          | â†“ 1.4                      |
| Precision         | â†‘ 0.95                     |
| Recall            | â†‘ 0.92                     |
| mAP@0.5           | â†‘ 0.98                     |
| mAP@0.5:0.95      | â†‘ 0.60                     |

**GrÃ¡fico de desempenho durante o treinamento:**

![Desempenho YOLOv3](./figuras/desempenho_treinamento.png)

ğŸ§  ConclusÃ£o
O modelo YOLOv3 foi eficaz para detectar cabeÃ§as de trigo, mesmo em imagens com objetos pequenos e agrupados. O uso da resoluÃ§Ã£o 640x640 contribuiu para a precisÃ£o das detecÃ§Ãµes. As mÃ©tricas obtidas demonstram que a soluÃ§Ã£o tem potencial para aplicaÃ§Ãµes reais na agricultura.

ğŸ“Œ Trabalhos Futuros
- Testar versÃµes mais recentes como YOLOv5 ou YOLOv8
- Melhorar o prÃ©-processamento com aumentos de dados (data augmentation)
- Otimizar o pÃ³s-processamento para reduzir falsos positivos
- Explorar aplicaÃ§Ãµes embarcadas para drones ou dispositivos agrÃ­colas

ğŸ™‹â€â™‚ï¸ Autores
Pedro Henrique Vogado Maia

LicenÃ§a AcadÃªmica
## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido exclusivamente para fins acadÃªmicos e educacionais.

Ã‰ permitido:
- Usar, estudar e modificar o cÃ³digo para fins de aprendizado e pesquisa.
- Compartilhar o projeto com atribuiÃ§Ã£o de autoria.

NÃ£o Ã© permitido:
- Utilizar este projeto para fins comerciais ou lucrativos sem autorizaÃ§Ã£o prÃ©via.
- Distribuir versÃµes modificadas sem citar a fonte original.

Â© 2025 - Pedro Henrique Vogado Maia. Todos os direitos reservados.
